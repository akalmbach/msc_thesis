\documentclass[12pt,Bold,TexShade]{mcgilletdclass}
\usepackage[pdftex]{graphicx}
\usepackage{subfig}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{listings}
\usepackage{color}
\usepackage[labelformat=simple]{caption}
\usepackage[dvips]{geometry}
\usepackage{amsmath}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\usepackage{amssymb}
\usepackage{url}
\usepackage{siunitx}
\usepackage{appendix}
\usepackage{hyperref}
\usepackage{natbib}

\usepackage{todonotes}

% \renewcommand\thesubfigure{\alph{subfigure})}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Have you configured your TeX system for proper  %%
%% page alignment? See the McGillETD documentation %%
%% for two methods that can be used to control     %%
%% page alignment. One method is demonstrated      %%
%% below. See documentation and the ufalign.tex    %%
%% file for instructions on how to adjust these    %%
%% parameters.                                     %%
\addtolength{\hoffset}{0pt}                        %%
\addtolength{\voffset}{0pt}                        %%
%%                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%       Define student-specific info
\SetTitle{\huge{Unsupervised Learning of Interpretable Models for Sparse, Smooth Data}}%
\SetAuthor{Arnold Kalmbach}%
\SetDegreeType{Master of Computer Science (Thesis)}%
\SetDepartment{Department of Computer Science}%
\SetUniversity{McGill University}%
\SetUniversityAddr{Montreal, Quebec}%
\SetThesisDate{\today}%
\SetRequirements{A thesis submitted to McGill University in partial fulfillment of requirements for
the degree of Master of Computer Science}%
\SetCopyright{\copyright{Arnold Kalmbach, 2018}}%

% \makeindex[keylist]
% \makeindex[abbr]

%% Input any special commands below
%\newcommand{\Kron}[1]{\ensuremath{\delta_{K}\left(#1\right)}}
\listfiles%
\begin{document}

\maketitle%

\begin{romanPagenumber}{2}%
\SetDedicationName{DEDICATION}%
\SetDedicationText{TODO TODO TODO}%
\Dedication%

\SetAcknowledgeName{ACKNOWLEDGEMENTS}%
\SetAcknowledgeText{TODO TODO TODO}%
\Acknowledge%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%         English Abstract                        %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\SetAbstractEnName{ABSTRACT}%
\SetAbstractEnText{
% \todo{Are you sure "maps" is the right term for the abstract?  As opposed to either "mappings", or "image manifolds",m or "sensorial maps", or maybe "image mappings"?}
This thesis considers learning unsupervised representations that facilitate understanding how complex data varies over space and time -- in other words learning interpretable semantic spatio-temporal map representations. We focus on representations that are \emph{sparse}, meaning most locations are described by few types, and \emph{smooth}, meaning most locations are described by the same types as their neighbors. We investigate how a spatio-temporal topic model -- a descendent of Latent Dirichlet Allocation (LDA) and other probabilistic latent variable models -- can be used to learn such representations for problems outside the typical text domain associated with LDA. We apply spatio-temporal topic models to a broad range of domains including modelling ambient audio, phytoplankton populations, and images observed by a robotic camera. In developing this variety of applications, we introduce novel interpretations of the learned topic model; beyond simple clustering or unsupervised classification we also consider using the topic model to make predictions in feature space and in the space of raw observations. In our experiments we demonstrate that sparse and smooth map representations are more interpretable than alternative unsupervised representations. We evaluate this interpretability in terms of both alignment with natural human-centric representations as well as the ease of learning later supervised models.
}
\AbstractEn%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%         French Abstract                         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\SetAbstractFrName{ABR\'{E}G\'{E}}%
\SetAbstractFrText{TODO TODO TODO}%
\AbstractFr%

\TOCHeading{TABLE OF CONTENTS}%
\LOTHeading{LIST OF TABLES}%
\LOFHeading{LIST OF FIGURES}%

\tableofcontents %
\listoftables %
\listoffigures %

\begin{center}
LIST OF SYMBOLS\\
\begin{tabular}{cp{\textwidth}}
  $x$ & Location, spatial or spatio-temporal \\
  $w$ & Word, an instance of a discrete-valued feature ($\textbf{w}$, all words) \\
  $z$ & Topic assignment ($\textbf{z}$, all topic assignments) \\
  $g(x)$ & The neighborhood of location $x$ \\
  $g$ & Parameter controlling neighborhood size \\
  $\theta$, $\theta_{g(x)}$ & Topic prior for one neighborhood ($\Theta$, all topic priors)\\
  $\phi$, $\phi_k$ & Word distribution for one topic ($\Phi$, all topics) \\
  $\alpha$ & Parameter of symmetric Dirichlet prior on $\theta$ \\
  $\beta$ & Parameter of symmetric Dirichlet prior on $\phi$ \\
  $K$ & Number of topics \\
  $V$ & Vocabulary size, number of distinct values of $w$ \\
  $N_{g(x)}^k$ & Number of times topic $k$ was used in neighborhood $g(x)$ \\
  $N_k^v$ & Number of times topic $k$ was used for word $v$ \\
  $N_{\cdot,-i}^\cdot$ & Count as above, but excluding the $i$-th datapoint\\
  $\sigma$ & The softmax function where the $i$-th dimension $\sigma(x)_i = {e^{x_i}} / \sum_j e^{x_j}$ \\
  $H[X]$ & Entropy of the random variable $X$: \\
         & $\mathbb{E}[-\log P(x)]$ \\
  $D_{KL}[P,Q]$ & KL-Divergence (information gain) of PMFs $P, Q$:\\
         & $\mathbb{E}_X \left[\log P(x) - \log Q(x) \right]$ \\
  $MI[X,Y]$ & Mutual information between random variables $X, Y$:\\
         & $\mathbb{E}_X \left[\mathbb{E}_Y \left[P(x,y) \log\left(\frac{P(x,y)}{P(x)P(y)}\right) \right] \right]$
\end{tabular}
\end{center}

\end{romanPagenumber} 

\mainmatter %
\include{intro}
\include{topic_model}
\include{classification}
\include{plankton}
\include{ptz}
\include{conclusion}
\include{appendices}

\bibliographystyle{chicagoa}
\bibHeading{References}
\bibliography{thesis}

%\index[abbr]{IEEE@IEEE: Institute of Electrical and Electronics Engineers, Inc.}
%\index[abbr]{CDMA@CDMA: code-division multiple access}
%\index[abbr]{CTAN@CTAN: comprehensive \protect\TeX{} archive network}

%\printindex[keylist]{Index}{Index}{}
%\printindex[abbr]{KEY TO ABBREVIATIONS}{KEY TO ABBREVIATIONS}{}

\end{document}
