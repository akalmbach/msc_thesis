%!TEX root = thesis.tex
\chapter{Introduction} \label{ch:intro}

\section{Context}
A fundamental goal of machine learning is to generate understanding for rich, high-dimensional datasets.
In many cases, pairs of inputs and desirable outputs are available for training, leading to techniques and representations directly equipped with external meaning by imitation. However in many other cases the desireable outputs are unavailable; For example, when a robot explores a new type of environment for the first time, when a scientist is encountered with a new type of data, or when one algorithm is presented with a novel learned representation produced by another algorithm (all examples discussed in detail within this thesis).

Unsupervised learning is an area of machine learning that aims to address this type of situation. Classic methods include Principal Component Analysis (PCA) and k-means clustering, and are both efficient to train and relatively straightforward to interpret. PCA learns a linear projection of the data based on the eigenvectors of the training data, \emph{ie.} a basis for the directions of greatest variance, while k-means clusters data-points by approximately minimizing the distance to cluster centers. Unfortunately, these approaches are too simplistic to capture natural categories in real data such as images, text documents or audio.

Many more recent techniques employ deep neural networks (DNNs) to define more expressive unsupervised models; Restricted Boltzmann Machines (RBMs), autoencoders, and Generative Adversarial Networks (GANs) are model families of particular note for impressive performance on large-scale unsupervised learning tasks with real data \citep{Bengio2013,Goodfellow2014}. In general, these approaches use a sequence of non-linear activations trained by stochastic gradient descent to find a low dimensional representation of the data which preserves as much information about it as possible. Such `Representation learning' techniques have been shown to be powerful as early computation stages for later supervised learning tasks. However, typically the downstream supervised tasks are solved with complex models (often another DNN) rather than simple ones. Although these methods achieve impressive performance in an absolute sense, the representations themselves are opaque and resist human interpretation. Even when regularization steps are added, the significance of a feature dimension with respect to a `semantic dimension' is rarely natural.

A final group of unsupervised learning techniques are those that are explicitly constructed as Bayesian probabilistic graphical models (PGMs). These models take the data $\textbf{x}$ and hypothesize related hidden variables $\textbf{z}$ used as the learned representation, along with a joint distribution that factors into a conditional likelihood and a prior, $P(\textbf{x}, \textbf{z}) = P(\textbf{x}|\textbf{z}) P(\textbf{z})$. The representation for a data point is produced by posterior inference, for example choosing $z = \argmax_z P(z | x)$. This group is not mutually exclusive with the previous two: PCA can be interpreted as a PGM with a single latent multivariate normal variable \citep{Bishop1999}, k-means can be interpreted as a special case of the well-known Gaussian Mixture Model  \citep{BishopCh9}, and autoencoders with a particular form can be trained for approximate posterior inference with particular choices of likelihood and prior \citep{Kingma2014}. The essential feature of the Bayesian graphical model formalism is that it provides a mechanism to control the types of representations we would like to obtain without hard constraints, allowing models to take advantage of both weak domain knowledge and very general priors on the kinds of representations that can be easily interpreted.

\section{Scope}
In this thesis we consider Bayesian unsupervised learning for spatial, temporal, or spatio-temporal data, in other words, for a dataset lacking associated labels but with associated locations. We hypothesize that by choosing an appropriate prior we can learn to represent data in ways that are accurate without sacrificing interpretability. In particular, our work centers on Realtime Online Spatio-temporal Topic models (ROST) \citep{Girdhar2014}, a descendant of Latent Dirichlet Allocation (LDA) \citep{Blei2003} which favors representations that are simple and spatio-temporally smooth. In Ch.~\ref{ch:topic-models-detail} we provide a comprehensive review of the spatio-temporal topic model.

Using the spatio-temporal topic model, we address learning unsupervised representations of spatio-temporal data which are compatible with simple downstream learning tasks and human interpretations. We hypothesize that if the raw data is transformed by an appropriate feature function and modeled with our approach, the learned representation can be aligned with human labels using a simple matching scheme. In addition, we consider scenarios where there are no manually-generated labels whatsoever and consider how the topic model may be used to gain intuitive insight into the factors that affect the data in the feature space directly.

\section{Motivation}
The introduction of cheap commercial GPS receivers and improvements in inertial and visual state estimation has resulted in an ever expanding set of data sources which come with associated spatial data. In the context of robotics, in addition to classic obstacle based landmark and occupancy maps, it is advantageous for a robot to have a qualitative sense of what kind of place it is in. For instance it would be prudent for a flying robot to recognize whether it is over park-, industrial-, or residential- land and modify its behavior for the appropriate balance of caution and efficiency. Nevertheless, these types may appear vastly different in different regions and with different cameras (or completely distinct sensor modalities), therefore the robot should be able to learn to differentiate these types autonomously and with as little manual human labelling as possible. We note that when people manually map such categories, the maps feature spatially coherent regions, and a central theme of our work is to exploit this simplification of the learning problem.

In addition to robot mapping problems, we are interested in scientific mapping and forecasting problems, and in particular focus on issues in the marine sciences. These applications often involve novel or otherwise unusual sensor data. Further, an intuitive simplification of the data may not be known ahead of time to use to produce a training set, or else producing one requires extremely specialized expertise to generate, and is therefore impractical in the required size. We aim to address these two issues by using unsupervised learning, and constraining our representations to those with spatio-temporally coherent regions. Rather than replacing more traditional statistical methods involved in the marine sciences, we envision this unsupervised system as a tool to generate intuitions and suggest hypotheses to test in more detail.

More generally, there is often a gap between measurements we can take (eg. images, sound, raw sensor data, etc.) and the regions that we want to map. Data requirements to learn a fully-supervised mapping to from these measurements to interpretable regions are often impractical, therefore we seek to let unsupervised methods do as much of the work as possible, simplifying the supervised learning task. Although we focus mainly on robotics and scientific applications, we note the opportunity to understand semantic regions in many aspects of public and personal life through the ubiquity of location as a field in data produced by smartphones and other mobile devices.

In addition to finding abstract high-level representations of data, we are interested in finding spatially coherent representations of datasets in their original domain. These applications arise when input data are in terms of a meaningful yet complex feature space, for example a classifier with a large number of potential outputs. To make this more concrete, consider a toy scenario: You are driving down the highway and can observe the buildings near each exit as you pass it. As you do so, if you build a model of the types of buildings that are often found at the same exit you will find groupings corresponding to residential areas, commercial areas, industrial parks etc. Even if you do not have any previous experience about what these categories mean, as you are driving you can use this information to make predictions about the buildings you will find. For instance, if you see a book store and a restaurant before the exit, you can guess you will be likely to find a movie theater nearby as well and choose to take the exit before actually seeing the type of building you were looking for. In addition, learning to associate external factors with the higher-level categories is simpler than with the more varied building types. And finally, the degree to which the exit fits into one of your high-level categories can tell you about how well you understand the neighborhood near an exit. Each of these tasks is simplified if the model distinguishes the buildings that can be explained by their location and spatial context from those which are explained by other factors, and whose location is effectively random.

\section{Contributions}
Our main contribution is a demonstration of the breadth of problems for which spatio-temporal topic models can provide interpretable representations. We apply spatio-temporal topic models to a variety of unsupervised learning problems in distinct domains and demonstrate that their representations outperform more direct unsupervised baselines. We demonstrate that our approach can be used to generate a simplified map (or timeseries) representation of the data, with naturally occurring mostly-disjoint regions. The applications presented in this thesis each explore the hypothesis that such a map contains an ideal economy of information, preserving detail while also being congruent with human explanations and compatible with simple downstream supervised learning problems.

Choosing a feature representation is one of the key challenges of working with topic models. The feature is the lowest level of observation present in the probabilistic structure of the PGM, and as a result common cross-validation metrics like the log probability of held-out data are not meaningful across different feature representations. Nevertheless, the feature representation is an important mechanism to ensure the learned model reflects the desired semantic representation of the data. In this thesis we extensively discuss how to choose a feature function for various domains and applications as well as how to learn an appropriate feature function in detail.

Finally, our work demonstrates how topic model outputs can be used more broadly than previous work. Because we apply topic models in a wide variety of domains, we find that different applications require distinct interpretations of the learned parameters. In addition to the aforementioned semantic-region maps, we enable applications where it is advantageous to use the topic model to produce predictions in the original feature space. We demonstrate approaches which make these predictions using auxiliary data, fill missing feature data with these predictions, and predict features for locations which we have not yet observed. These approaches enable insight into the feature space of each application.
\todo[inline]{redundant with the example in the previous section? rework}

\section{Thesis Outline}

This thesis is organized according to incrementally more complex topic model applications.
First, we review the spatio-temporal topic model, formally outlining its generative model and assumptions, and why they lead to interpretable models in Ch.~\ref{ch:topic-models-detail}. Then, in Ch.~\ref{ch:topic-models-examples} we give two example applications demonstrating that careful choice of a feature function combined with the model's assumptions can be used to produce topic assignments that align with independently generated hand labelling. This work in this chapter is most closely related to previous applications of the spatio-temporal topic model and topic models in general.

After we have developed tools to directly interpret the learned map representations, we explore applications where predictions must be made in the space of the original observations. In Ch.~\ref{ch:plankton} we explore how spatio-temporal topic models can be used to gain insight into a novel scientific dataset. In contrast to the preceding examples, rather than gaining insights in the abstract topic domain, we we prefer them in the feature domain. We develop tools to predict feature distributions from topic priors, and to approximate topic priors from external data. A central theme in this chapter is that because the topic priors are encouraged to be interpretable, they are easier to predict from auxillary data than feature distributions.

Finally, in Ch.~\ref{ch:spatial-prediction} we consider using spatio-temporal topic models and active vision to make spatial predictions in the image domain, rather than the image feature domain. We develop a convolutional autoencoder architecture such that its latent space gives a suitable image feature distribution function for a topic modelling. We extend the feature prediction methods of Ch.~\ref{ch:plankton} and demonstrate how a spatio-temporal topic model can be used to interpolate between camera perspectives using our topic model's predicted features and our autoencoder's decoder stage. We also explore how the topic model can be used to make spatial predictions about quantity of information, effectively allowing our model to seek out views with the most interesting content.
