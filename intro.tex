%!TEX root = thesis.tex
\chapter{Introduction} \label{ch:intro}

% \todo[inline]{Would be nice to have an illustration of the approach in the introduction if time allows, but it's not critical by any means.}
\section{Context}
A fundamental goal of machine learning is to generate useful representations of rich, high-dimensional datasets, simplifying human understanding by learning to transform data. In many cases the goal of these representations is to imitate a training dataset with both inputs and labels, often generated by substantial manual annotation effort.
In many other cases however, a dataset of these labels is unavailable; For example, when a robot explores a new type of environment for the first time, when a scientist is encountered with a new type of data, or when one algorithm is presented with a novel learned representation produced by another algorithm (all examples discussed in detail within this thesis).
% \todo[inline]{I find this preceding phrase a bit cryptic, at least if one does not ALREADY know what you mean}
% \todo[inline]{Stylistically, I think it is better never to start a sentence with "However". Thus this could be "In many other cases, however, ..."}

% \todo[inline]{"address this lack" => "achieve learning despite the absence of labelled data" (i.e. it does not actually "address the lack:, rather it circumvents the need for labels.}
Unsupervised learning is an area of machine learning that aims to circumvent the need for manual annotation, learning useful representations despite the absence of labelled data. Classic methods include Principal Component Analysis (PCA) and k-means clustering, and are both efficient to train and relatively straightforward to interpret. Unfortunately, these approaches are too simplistic to capture natural categories in data such as images, text documents or audio that are most prevalent and interesting in human-oriented applications. PCA simply learns a linear projection based on the eigenvectors of the training data, i.e. a basis for the directions of greatest variance, while k-means just clusters data-points by approximately minimizing the distance to cluster centers. Although widely applicable, more elaborate methods are needed to capture detail in large datasets of widely varying data.
% \todo[inline]{I do not really disagree but I find this a bit strong. Keep it if you want, but I would prefer weaker language since it may well be that {\bf most} interesting data sets ARE captured by these methods and they aren't you do not have any real evidence of that conjecture.}

In contrast, more recent unsupervised learning techniques employ deep neural networks (DNNs) to define more expressive unsupervised models; Restricted Boltzmann Machines (RBMs), autoencoders, and Generative Adversarial Networks (GANs) are model families of particular note for impressive performance on large-scale unsupervised learning tasks with real data \citep{Bengio2013,Goodfellow2014}.  In general, these approaches use a sequence of non-linear activations trained by stochastic gradient descent to find a low dimensional representation of the data which preserves as much information about it as possible. Such `representation learning' techniques have been shown to be powerful as early computation stages for later supervised learning tasks. However, typically these supervised tasks are typically solved with complex models (often another DNN) rather than simple ones. Although these methods achieve impressive performance in an absolute sense, the representations themselves are opaque and resist human interpretation. Even when regularization steps are added, the significance of a feature dimension with respect to a `semantic dimension' is rarely natural.

A final group of unsupervised learning techniques are those that are deliberately constructed as Bayesian probabilistic graphical models (PGMs). These models take the data $\textbf{x}$ and hypothesize related hidden variables $\textbf{z}$ used as the learned representation, along with a joint distribution that factors into a conditional likelihood and a prior, $P(\textbf{x}, \textbf{z}) = P(\textbf{x}|\textbf{z}) P(\textbf{z})$. The representation for a data point is produced by posterior inference, for example choosing $z = \argmax_z P(z | x)$. This group is not mutually exclusive with the previous two: PCA can be interpreted as a PGM with a single latent multivariate normal variable \citep{Bishop1999}, k-means can be interpreted as PGM by its equivalence to a special case of the well-known Gaussian Mixture Model  \citep{BishopCh9}, and autoencoders with a particular form can be trained for approximate posterior inference with particular choices of likelihood and prior \citep{Kingma2014}. The essential feature of the Bayesian graphical model formalism is that it provides a mechanism to control the types of representations we would like to obtain without hard constraints, allowing models to take advantage of both weak domain knowledge and very general priors on the kinds of representations that can be easily interpreted.

\section{Scope}
In this thesis we consider Bayesian unsupervised learning for spatial, temporal, or spatio-temporal data, in other words, for a dataset lacking associated labels but with associated locations. We hypothesize that by choosing an appropriate prior we can learn to represent data in ways that are accurate without sacrificing interpretability. In particular, our work centers on Realtime Online Spatio-temporal Topic models (ROST) \citep{Girdhar2014}, a descendant of Latent Dirichlet Allocation (LDA) \citep{Blei2003} which favors representations that are simple and spatio-temporally smooth. In Ch.~\ref{ch:topic-models-detail} we provide a comprehensive review of the spatio-temporal topic model.

Using the spatio-temporal topic model, we address learning unsupervised representations of spatio-temporal data that are compatible with simple downstream learning tasks and human interpretations. We hypothesize that if raw data is transformed by an appropriate feature function and modeled with our approach, the representation learned by the spatio-temporal topic model can be aligned with human labels using a simple matching scheme. In addition, we consider scenarios where there are no manually-generated labels whatsoever and consider how the topic model may be used to gain intuitive insight into the factors that affect the data in the feature and raw data domains directly.

\section{Motivation}
The introduction of cheap commercial GPS receivers and improvements in inertial and visual state estimation has resulted in an ever expanding set of data sources which come with associated spatial data. In the context of robotics, in addition to classic obstacle based landmark and occupancy maps, it is advantageous for a robot to have a qualitative sense of what kind of place it is in. For instance it would be prudent for a flying robot to recognize whether it is over park, industrial, or residential land and modify its behavior for the appropriate balance of caution and efficiency. Nevertheless, these types of land may appear vastly different in different regions and with different cameras (or completely distinct sensor modalities), therefore a robot should be able to learn to differentiate between them autonomously, and it should do so with as little manual human labelling as possible. We note that when people manually draw such label maps, the categories form spatially coherent regions; a central theme of our work is to exploit this simplification of the space of relevant representations.

In addition to robot mapping problems, we are interested in scientific mapping and forecasting problems, and in particular focus on issues in the marine sciences. These applications often involve novel or otherwise unusual sensor data. Further, an intuitive simplification of the data may not be known ahead of time to use to produce a training set, or else producing may require extremely specialized expertise, and therefore be impractical in the required size. We aim to address these two issues by using unsupervised learning, and constraining our representations to those with spatio-temporally coherent regions. Rather than replacing more traditional statistical methods involved in the marine sciences, we envision this unsupervised system as a tool to generate intuitions and suggest hypotheses that domain researchers can choose to test in more detail.

More generally, there is often a gap between measurements we can take (eg. images, sound, raw sensor data, etc.) and the regions that we want to map. Data requirements to learn a fully-supervised mapping to from these measurements to interpretable regions are often impractical, therefore we seek to let unsupervised methods do as much of the work as possible, simplifying the supervised learning task. Although we focus mainly on robotics and scientific applications, we note the opportunity to understand semantic regions in many aspects of public and personal life through the ubiquity of location as a field in data produced by smartphones and other mobile devices.

In addition to finding abstract high-level representations of data, we are interested in finding spatially coherent representations of datasets in their original domain. These applications arise when input data are in terms of a meaningful yet complex feature space, for example a classifier with a large number of potential outputs. To make this more concrete, consider a toy scenario: You are driving down the highway and can observe the buildings near each exit as you pass it. As you do so, if you build a model of the types of buildings that are often found at the same exit you will find groupings corresponding to residential areas, commercial areas, industrial parks etc. Even if you do not have any previous experience about what these categories mean, as you are driving you can use this information to make predictions about the buildings you will find. For instance, if you see a book store and a restaurant before the exit, you can guess you will be likely to find a movie theater nearby as well, and could choose to take the exit based on this prediction before actually seeing your destination.
In addition, building a model of associations between each building type and other observations you can make would require extensive experience, but if you already know which buildings are associated with one another, this requirement is lessened. In this scenario, although the high-level categories are not necessarily aligned with any human semantics, they are still useful for another model to use to make concrete predictions.

\section{Contributions}
Our main contribution is a demonstration of the breadth of problems for which spatio-temporal topic models can provide interpretable representations. We do this by making original contributions in terms of the application of topic models in several different domains. We apply spatio-temporal topic models to a variety of unsupervised learning problems in distinct domains and demonstrate that their representations outperform more direct unsupervised baselines. We demonstrate that our approach can be used to generate a simplified map (or timeseries) representation of the data, with naturally occurring mostly-disjoint regions. The applications presented in this thesis each explore the hypothesis that such a map contains an ideal economy of information, preserving detail while also being congruent with human explanations and compatible with simple downstream supervised learning problems.

Choosing a feature representation is one of the key challenges of working with topic models. The feature is the lowest level of observation present in the probabilistic structure of the PGM, and as a result common cross-validation metrics like the log probability of held-out data are not meaningful across different feature representations. Nevertheless, the feature representation is an important mechanism to ensure the learned model reflects the desired semantic representation of the data. In this thesis we extensively discuss how to choose a feature function for various domains and applications as well as how to learn an appropriate feature function in detail.

Finally, our work demonstrates how topic model outputs can be used more broadly than previous work. Because we apply topic models in a wide variety of domains, we find that different applications require distinct interpretations of the learned parameters. In addition to the aforementioned semantic-region maps, we enable applications where it is advantageous to use the topic model to produce predictions in the original feature space. We demonstrate approaches which make these predictions using auxiliary data, fill missing feature data with these predictions, and predict features for locations which we have not yet observed. Further, we develop a method to learn features that are both good for topic modelling and invertible back to their original domain. This invertible feature representation allows us to directly view and evaluate what our model has learned as images, a much more intuitive representation than a bag-of-words in a vision context.

\section{Thesis Outline}

This thesis is organized according to incrementally more complex topic model applications. First, in Ch.~\ref{ch:topic-models-detail}, we review the spatio-temporal topic model, formally outlining its generative model and assumptions, and why they lead to interpretable models. Then, in Ch.~\ref{ch:topic-models-examples} we give two example applications demonstrating that careful choice of a feature function combined with the model's assumptions can be used to produce topic assignments that align with independently generated hand labelling. The work in this chapter is most closely related to previous applications of the spatio-temporal topic model and topic models in general.

After we have developed tools to directly interpret the learned representations, we explore applications where predictions in a more concrete domain are necessary. In Ch.~\ref{ch:plankton} we explore how spatio-temporal topic models can be used to gain insight into a novel scientific dataset. In contrast to the preceding examples, rather than gaining insights in the abstract topic domain, we we prefer them in the feature domain. We develop tools to predict feature distributions from topic priors, and to approximate topic priors from external data. A central theme in this chapter is that because the topic priors are encouraged to be interpretable, they are easier to predict from auxillary data than feature distributions.

Finally, in Ch.~\ref{ch:spatial-prediction} we consider using spatio-temporal topic models make spatial predictions in the image domain, rather than the image feature domain. We develop a convolutional autoencoder architecture such that its latent space gives a suitable image feature distribution function for topic modelling. We extend the feature prediction methods of Ch.~\ref{ch:plankton} and demonstrate how a spatio-temporal topic model can be used to interpolate between camera perspectives using our topic model's predicted features and our autoencoder's decoder stage. By using this method, we are able to evaluate the topic model in terms of the quality of its image predictions. Further, this approach allows us to create a unique, intutive interface to explore what the topic model has learned and search for images based on a mixture of topics represented as images.
